{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c50d0534-436b-4ca3-80fa-340c4b4a2ead",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-12T19:28:58.497573Z",
     "iopub.status.busy": "2023-10-12T19:28:58.496574Z",
     "iopub.status.idle": "2023-10-12T19:28:58.515065Z",
     "shell.execute_reply": "2023-10-12T19:28:58.513545Z",
     "shell.execute_reply.started": "2023-10-12T19:28:58.497573Z"
    },
    "tags": []
   },
   "source": [
    "<div style=\"text-align: center;\" >\n",
    "<h1 style=\"margin-top: 0.2em; margin-bottom: 0.1em;\">Introduction to Computation for the Social Sciences</h1>\n",
    "<h2 style=\"margin-top: 0.7em; margin-bottom: 0.3em;\">Assignment 3</h2>\n",
    "<h3 style=\"margin-top: 0.7em; margin-bottom: 0.3em;\">Deadline: 22.12.2024 12:00 pm</h3>\n",
    "\n",
    "</div>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c331da00-ae95-4f9a-ba1a-7df50558b58e",
   "metadata": {},
   "source": [
    "<h4 style=\"margin-top: 0.7em; margin-bottom: 0.3em; font-style:italic\">\n",
    "Please push your solutions to your personal repository in our <a href='https://classroom.github.com/a/tGD_7t85'>GitHub Classroom</a></h4><br>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a03996-1421-4f37-a555-e5945634772b",
   "metadata": {},
   "source": [
    "This assignment will test your knowledge in object oriented programming (OOP), your understanding of regular expressions (regexes), and finally we will have you perform sentiment analysis.<br>\n",
    "As always: In case of questions feel free to reach out to us tutors in person, via mail, or over discord.<br>\n",
    "***Important: Submit a solution for every single task and do not skip any of them. Even if your solution is not perfect or doesn't work you might still receive some points that way!***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb213ad-f59c-45e9-b8f7-75b3910be47a",
   "metadata": {},
   "source": [
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38639719-207a-4192-a784-ce57072d170c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T15:22:14.892836Z",
     "iopub.status.busy": "2023-12-12T15:22:14.892836Z",
     "iopub.status.idle": "2023-12-12T15:22:14.895933Z",
     "shell.execute_reply": "2023-12-12T15:22:14.895407Z",
     "shell.execute_reply.started": "2023-12-12T15:22:14.892836Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import the modules you use throughout the assignment here (this is called a setup chunk/cell)\n",
    "# e.g import pandas as pd\n",
    "# e.g import numpy as np and so on...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4811d77-1ca4-49a8-ae2f-7cc044d94d2f",
   "metadata": {},
   "source": [
    "# Part 1 - Object Oriented Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6880a6dc-180c-4f59-99b5-2a036d16e964",
   "metadata": {},
   "source": [
    "## Task 1.1\n",
    "\n",
    "\n",
    "The [Dog API](https://dogapi.dog/docs/api-v2) is a simple and easy to use tool to get information about certain dog breeds along with random facts about dogs.<br>\n",
    "Use the API to create a class `DogBreed`.\n",
    "- This class takes as input the name of a dog breed (e.g. 'Caucasian Shepherd Dog' or 'Bouvier des Flandres')\n",
    "- Implement a class method `get_breed_info()`that returns a description of input dog breed\n",
    "- Implement a class method `get_max_age()`that returns the maximum life expectancy of the input dog breed\n",
    "- Implement a class method `get_fact()`that returns a random fact about dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e3181c-41f1-4f75-b5c8-8fab85400b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19167c7-100f-46ec-91d4-2fe84731c0e2",
   "metadata": {},
   "source": [
    "## Task 1.2 - Bonus\n",
    "\n",
    "\n",
    "The class `DogBreed` you created in task 1.1 is probably pretty simple. To remedy this, please implement a system that catches exceptions and deals with them appropriately. For this you will have to think about the types of exceptions someone using the `DogBreed` class might encounter and how you want to deal with each of them.<br>\n",
    "Feel free to do additional on how to handle exceptions as we did not cover them in much detail. You can get a nice overview, for example, [here](https://www.w3schools.com/python/python_try_except.asp).<br>\n",
    "Please copy paste your code from above and implement exception handling below. Of course you can also just rewrite the class ;)\n",
    "\n",
    "***Tip:***\n",
    "Error handling is usually done something like this in python:<br>\n",
    "```\n",
    "try:\n",
    "    some_code\n",
    "    return some_var\n",
    "except error1 as e:\n",
    "    handle specific exception\n",
    "except error2 as e:\n",
    "    handle specific exception\n",
    "except:\n",
    "    handle general exception\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab68e343-9473-4ff6-bc9a-add0ffbd4f7f",
   "metadata": {},
   "source": [
    "Before you start to code, as mentioned above, you will have to think about the different exceptions someone might encounter and how you would deal with them.\n",
    "E.g.:<br>\n",
    "Person tries to use method that is not implemented -> print('This method does not exist for class DogBreed')...<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d742a53c-188e-49ac-946e-a12e10f27bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a71040c-758d-4269-8ff8-eb1f552c81ca",
   "metadata": {},
   "source": [
    "***\n",
    "# Part 2 - Preprocessing & Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0672b9-bd4e-4fe0-b0a0-6dfe1681d8e1",
   "metadata": {},
   "source": [
    "In the assignemnt folder, you will find a cdc_whistleblower_tweets.zip containing a .json file with tweets from the CDC Whistleblower debate. The file consists of 272660 tweets containing the hashtag #CDCWhistleblower. In case you're interested in the data you can get some additional infos [here](https://www.snopes.com/fact-check/bad-medicine/).<br>\n",
    "\n",
    "You will need to process this file aka. the tweets in it in order to work with the data in task 3 & task 4.<br>\n",
    "***Hint: Use a sample of tweets in order to test your preprocessing steps before you run them on the whole data set (eg. 1000 tweets)***\n",
    "\n",
    "## Task 2.1\n",
    "\n",
    "In task 4 you will have to perform sentiment analysis on these tweets. Keeping that in mind please perform the following preprocessing operations on the data. <br>\n",
    "First, we will replace user mentions, extract hashtags and remove urls from the original text column \n",
    "To do so, you will need to use regular expressions.\n",
    "\n",
    "Create three functions:\n",
    "- `replace_mentions()`: a function that replaces all user mentions (@username) in the text column with '@user' (think of it as anonymizing the data). You are supposed to change the original text column here!\n",
    "- `extract_hastags()`: a function that extracts all hashtags (e.g. #CDCWhistleblower) appearing in the tweet and stores them in a new column `hashtags` without altering the original text column\n",
    "- `remove_urls()`: a function that extracts all domain names from the 'expanded_url' field (entities → urls → expanded_url) to a new column (e.g. [google.com, wikipedia.org, ...]) and removes the URLs from the original text colmn.<br>\n",
    "\n",
    "\n",
    "\n",
    "Before you get into coding take a moment and think about how you might use regular expressions to solve this task. \n",
    "Develop a regular expression for each of the three functions and shortly explain how it works - for example in the comments.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25542019",
   "metadata": {},
   "source": [
    "For this task, you might want to consider the [re module](https://docs.python.org/3/library/re.html).<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e1f8596-a86d-4160-8ab8-2f36ed35fa71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T19:43:29.414658Z",
     "iopub.status.busy": "2023-12-11T19:43:29.414658Z",
     "iopub.status.idle": "2023-12-11T19:43:29.419560Z",
     "shell.execute_reply": "2023-12-11T19:43:29.418544Z",
     "shell.execute_reply.started": "2023-12-11T19:43:29.414658Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da2bd77-6519-43c5-a9e2-60992a1f2a9f",
   "metadata": {},
   "source": [
    "## Task 2.2\n",
    "\n",
    "As a second step of preprocessing, we now want to normalize and tokenize the text as well as to remove stop words. \n",
    "These preprocessings should NOT change the original `text` column. Instead, write the functions and apply them in way that the result is stored in a new column `clean_tokens`. \n",
    "\n",
    "\n",
    "- Write a `normalize_text()` function that transforms all text to lower case\n",
    "- Write a `tokenize_text()` function that tokenizes the text aka. splits it into individual words\n",
    "- Write a `remove_stopwords()` function that removes all stopwords that are part of `eng_stop_words.txt`\n",
    "\n",
    "\n",
    "At the end, make sure you save the preprocessed data in a file so as not to have to run the preprocessing everytime you come back to the assignment. <br>\n",
    "Run the preprocessing on the whole data set. Save the preprocessed data as 'processed_tweets.json'.<br>\n",
    "\n",
    "This file will exceed the 100MB GitHub upload limit. You will have to create a compressed .zip directory containing the file in order to upload it. Before uploading you will then have to delete or move the uncompressed file from your personal repository. If you do not do this you won't be able to upload your submission.<br>\n",
    "Another solution would be to open the file '.gitignore' which we put in your personal repository at the start of the semester. There you will see '.ipynb_checkpoints/'. Copy the name of your .json file and add it as a new line to this '.gitignore' file (e.g. cdc_whistleblower_tweets.json). This will tell git to ignore the file and enable you to upload your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a070ec79-0c78-4726-bd69-12e845e58e74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T19:02:25.890805Z",
     "iopub.status.busy": "2023-12-11T19:02:25.889804Z",
     "iopub.status.idle": "2023-12-11T19:02:25.895275Z",
     "shell.execute_reply": "2023-12-11T19:02:25.894635Z",
     "shell.execute_reply.started": "2023-12-11T19:02:25.890805Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a5e8f6",
   "metadata": {},
   "source": [
    "## Task 2.3 - Bonus\n",
    "\n",
    "\n",
    "\n",
    "Building on your preprocessing in this task, print the data set's 10 most frequently occurring words/tokens, hashtags, and domain names.<br>\n",
    "Use the [wordcloud module](https://python-course.eu/applications-python/python-wordcloud-tutorial.php) to visualize your findings regarding words/tokens and hashtags. Create one plot for words/tokens and one for hashtags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82560fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3b6df4-aeb0-4f6a-851b-b1533d95ddc3",
   "metadata": {},
   "source": [
    "***\n",
    "# Part 3 - Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abfe80b-27ca-4a5a-966c-97bf25ec5345",
   "metadata": {},
   "source": [
    "Using the [Tkinter](https://docs.python.org/3/library/tkinter.html) library write the code for an application. This application is supposed to aid you in labelling texts according to their sentiment. For this you will need to implement certain functions into your app. Once your application is up an running sample 150 tweets from the CDCWhistleblower data set and label them using your app.<br>\n",
    "Save your sample as .json file and be sure to include the tweet_id for each tweet so you are able to compare your labels with the ones you get from running VADER in task 4.<br>\n",
    "Please use the original text for your labeling. After the preprocessing in task 2 it should not contain specific user mentions but only '@user', there should be no URLs left in the text, and #Hashtags should appear untouched in your texts.<br>\n",
    "\n",
    "***Hint: Before you actually start coding, a great approach is to first of all start by conceptualizing your small app. Think about which functionalities you need to have and how these depend on and call each other. You can, as an example, refer to the extended Tkinter example we covered in the tutorial.***\n",
    "If you like to, you can hand in your handwritten schema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfddd209",
   "metadata": {},
   "source": [
    "![Picture_of_schema](path_to_the_pic/pic.jpg) <-- **double click this cell to see how appending pictures with .ipynb files works. Make sure to hand in the png as well.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e925d42-9437-41ec-ba8b-f608a2fbada0",
   "metadata": {},
   "source": [
    "## Task 3.1\n",
    "\n",
    "\n",
    "In order for your application to work as intended follow the steps below. Note that this is no easy task! Work with other students, exchange ideas, or find help online but remember to only hand in code that you have written yourself!<br>\n",
    "\n",
    "Implement the application as a class:<br>\n",
    "- that takes 2 arguments: 'input_file' and 'output_file'\n",
    "- that supports the method `load_data()` which loads the output_file and the input_file and removes tweets that are already classified aka. part of the output file. This is to ensure that you won't label the same text twice and that you will reach an end, once every text got labeled once. \n",
    "- with method `start_app()` that runs your application with a text box showing the content (text) of a tweet and 4 labeling buttons (Positive, Negative, Neutral, Undecidable) used to classify the content of each tweet\n",
    "- with method `next_text()` that chooses a random tweet from the input data, displays it in the text box of the app and once the tweet has been classified, removes it from the pool of tweets still to be labeled<br>\n",
    "\n",
    "Feel free to implement any other methods you deem necessary and do not forget to comment and explain your code!<br>\n",
    "\n",
    "***Hint: There are many ways of solving this task! There is no 'one and only' solution so be bold and experiment with your ideas. You can probably make most of them work!***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb133e22-c428-419f-bda0-1615770b144a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T20:15:54.856419Z",
     "iopub.status.busy": "2023-12-11T20:15:54.856419Z",
     "iopub.status.idle": "2023-12-11T20:15:54.859376Z",
     "shell.execute_reply": "2023-12-11T20:15:54.859173Z",
     "shell.execute_reply.started": "2023-12-11T20:15:54.856419Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166477dd-2cec-49ec-bca0-db7049f1ffc2",
   "metadata": {},
   "source": [
    "## Task 3.2\n",
    "\n",
    "\n",
    "Use your application to classify your sample of 150 tweets from the CDCWhisleblower data and save your result as 'manually_labeled_tweets.json'.<br>\n",
    "Make sure you upload this labeled sample of tweets to your solutions repository!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1386b56-b758-4de1-a666-3636e031430d",
   "metadata": {},
   "source": [
    "***\n",
    "# Part 4 - Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7062d6e2-e2aa-4e79-97bc-60cf0c8638c5",
   "metadata": {},
   "source": [
    "In this last part of the assignment you will use the VADER sentiment analyzer to, well, analyze the sentiment of the CDCWhistleblower tweets.<br>\n",
    "You can find a tutorial of how the nltk module's VADER analyzer works [here](https://www.nltk.org/howto/sentiment.html).<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cce033-2802-4a5a-b446-d0dcd533113a",
   "metadata": {},
   "source": [
    "## Task 4.1\n",
    "\n",
    "\n",
    "Use the sentiment analyzer on the preprocessed original text column (the one without URLs, with @user, and #Hashtags) and save the resulting polarity score to a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82c53f2f-28d5-4b57-9b2b-0a16e4e2c9a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T16:01:17.513304Z",
     "iopub.status.busy": "2023-12-12T16:01:17.513304Z",
     "iopub.status.idle": "2023-12-12T16:01:17.516833Z",
     "shell.execute_reply": "2023-12-12T16:01:17.515827Z",
     "shell.execute_reply.started": "2023-12-12T16:01:17.513304Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723d9e50-11d8-42e5-8113-f12763866bed",
   "metadata": {},
   "source": [
    "## Task 4.2\n",
    "\n",
    "\n",
    "Create another column containing the VADER sentiment label for each tweet. You can get the label (positive, negative, neutral) by checking the polarity scores you got in task 4.1. If the polarity score is smaller 0 (<0) the label should be 'negative', if it is larger 0 (>0) the label should be 'positive', and otherwise the label should be 'neutral'.<br>\n",
    "What are the shares of 'positive', 'negative', and 'neutral' tweets? Visualize your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "427a6842-6203-4ff2-ba58-39bc87d2e898",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T16:03:48.297744Z",
     "iopub.status.busy": "2023-12-12T16:03:48.297744Z",
     "iopub.status.idle": "2023-12-12T16:03:48.301095Z",
     "shell.execute_reply": "2023-12-12T16:03:48.301095Z",
     "shell.execute_reply.started": "2023-12-12T16:03:48.297744Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823a5991-7dfb-4d23-866c-fd16b8e7e0b5",
   "metadata": {},
   "source": [
    "## Task 4.3\n",
    "\n",
    "\n",
    "\n",
    "Match the 150 tweets you labeled manually with the labels you got from applying the VADER sentiment analyzer to the data. Visualize how VADER performed at analyzing the sentiment against your manual classifications of these 150 tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dab2b2f-cb0d-4723-9cab-965f20968c3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T16:14:50.643198Z",
     "iopub.status.busy": "2023-12-12T16:14:50.643198Z",
     "iopub.status.idle": "2023-12-12T16:14:50.646359Z",
     "shell.execute_reply": "2023-12-12T16:14:50.646359Z",
     "shell.execute_reply.started": "2023-12-12T16:14:50.643198Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your code\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
